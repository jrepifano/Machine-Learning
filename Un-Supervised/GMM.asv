clear all; clc;
X = mvnrnd([2 5], [1 1], 100); %OG data
Y = mvnrnd([4 3], [1 1], 100);

Z = vertcat(X,Y);
Z1 = Z(:,1);
Z2 = Z(:,2);


meanx1 = mean(X); %calculate averages for each class
meanx2 = mean(Y);

sigmax1 = std(X); %calculate sigma for each class
sigmax2 = std(Y);

x = [0 00];
y = [8 8];
mus = [];
H = 10;
j = 0;
figure
hold on
plot(X(:,1),X(:,2),'.'); %plot
plot(Y(:,1),Y(:,2),'+');
title('K-Means Unsupervised Learning');
plot(x(:,1),x(:,2),'x','linewidth',8); %plot
plot(y(:,1),y(:,2),'x','linewidth',8);
axis([0 8 0 8]);
while(H > 1)
classx = [];
classy = [];
for i = 1:n
    
    Px11 = normpdf(Z1(i),meanx1(:,1),sigmax1(:,1)); %Calculate likelyhood for each feature, for each class
    Px12 = normpdf(Z2(i),meanx1(:,2),sigmax1(:,2));
    Px21 = normpdf(Z1(i),meanx2(:,1),sigmax2(:,1));
    Px22 = normpdf(Z2(i),meanx2(:,2),sigmax2(:,2));
    
    probx1 = Px11 * Px12; %Since we assume independence, the total probability is the union between both features
    probx2 = Px21 * Px22;
    
    if(probx1 > probx2)     %Keep track of what each test point was classified as

        classx = [classx;z(i,1) z(i,2)];    %Add points to matrix to graph
    
    elseif(probx1 < probx2)

        classy = [classy;z(i,1) z(i,2)];
        
    end
    
end
mus = [mus;x];
x = mean(classx);
y = mean(classy);
H = H -1 ;

figure
hold on
plot(X(:,1),X(:,2),'.'); %plot
plot(Y(:,1),Y(:,2),'+');
title('K-Means Unsupervised Learning');
plot(x(:,1),x(:,2),'x','linewidth',8); %plot
plot(y(:,1),y(:,2),'x','linewidth',8);
axis([0 8 0 8]);

end



hold off
